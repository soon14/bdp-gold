#============================spark-core配置项================================
#设置spark Streaming 应用程序的名字
spark.commons.appName = riskRuleBatch
#spark streaming 每个RDD的分区数（注意配置成kafka topic的分区数）
spark.commons.RDD.num = 10
#spark程序是否优雅的关闭(把接收到的数据处理完毕再关闭spark程序)
spark.commons.gracefully.stop = true
#设置系统打印日记的水平
spark.commons.logLevel= WARN
#设置spark程序的序列化方式(默认java自带)
spark.serializer = org.apache.spark.serializer.KryoSerializer
#内存用来存储的比例,这部分内存中有多少可以用于Memory Store管理RDD Cache的数据
spark.storage.memoryFraction = 0.2
#是否开启调整内存存储比例功能
spark.memory.useLegacyMode = true
#set user memory在整个 executor memory 的占比。（默认 0.6 -> 0.2)，也可调大 executor memory来增加 user memory
spark.memory.fraction = 0.6
#checkpoint的路径和目录(暂定必填)
spark.commons.checkpoint = /user/spark/rule/checkpoint
#spark Streaming Dstream调度的时间间隔（单位为秒,默认为5秒）
saprk.streaming.schedulingInterval = 5
#============================spark-shuffle================================
#sparkStreaming.Shuffle.manager的类型(hash,sort)
spark.shuffle.manager = sort
#spark.shuffle缓存大小,默认32K 内存充足可以调到64,减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数
spark.shuffle.file.buffer = 64k
#spark shuffle read 拉取属于自己数据时重试的次数
spark.shuffle.io.maxRetries = 3
#spark shuffle read 拉取属于自己数据时重试的间隔
spark.shuffle.io.retryWait = 5s
#spark集群中每个executor中用来shuffle的等操作的内存大小最小比例。shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘
spark.shuffle.memoryFraction = 0.6
#======================kafka-config==============================
spark.streaming.realTime.kafkaTopics ="topic-app,topic-bbe"
#直接读取kafka channel 数据的brokers
#spark.streaming.kafkaBrokers ="cdh1.server.fjf:9092,cdh2.server.fjf:9092,cdh3.server.fjf:9092,cdh4.server.fjf:9092,cdh5.server.fjf:9092"
spark.streaming.kafkaBrokers ="slave1.cdh.fjf:9092,slave2.cdh.fjf:9092,slave3.cdh.fjf:9092,slave4.cdh.fjf:9092,slave5.cdh.fjf:9092"
#直接读取kafka channel 数据的偏移量的策略
spark.streaming.kafka.offsets = latest
#kafka channel 的 group id
spark.streaming.kafka.group.id = kafka-consumer-spark-2
#spark Streaming 设置每个kafka partition读取消息的最大速率（默认为0,其表示不限制）
spark.streaming.kafka.maxRatePerPartition = 5000
# 开启反压,限制每个batch接收到的消息量，降低数据倾斜的风险
spark.streaming.backpressure.enabled = true
#=======================mysql的配置====================
#链接mysql的jdbcURL
#spark.straming.jdbc.url ="jdbc:mysql://bdata-test-mysql.server.fjf:3306/fox-data?useUnicode=true&characterEncoding=utf8&useSSL=false"
spark.straming.jdbc.url ="jdbc:mysql://bdata-mysql.server.fjf:3306/fox-data?useUnicode=true&characterEncoding=utf8&useSSL=false"
#披量写mysql的批量大小
spark.streaming.connect.batch.size = 1000
#连接mysql的用户名
spark.streaming.jdbc.username="root"
#连接mysql的密码
spark.streaming.jdbc.password="data-TECH@platform!@"
#spark.streaming.jdbc.password="123456"
#jdbc driver
spark.streaming.jdbc.driver=com.mysql.jdbc.Driver
#kafka管理offset表
table.kafka.offset ="kafka_offset"

#=======================zookeeper====================
# zookeerper端口号
hbase.zookeeper.port="2181"
# zk集群
hbase.zookeeper.quorum="slave1.cdh.fjf,slave2.cdh.fjf,slave3.cdh.fjf,slave4.cdh.fjf,slave5.cdh.fjf"
#hbase.zookeeper.quorum="cdh1.server.fjf,cdh2.server.fjf,cdh3.server.fjf,cdh4.server.fjf,cdh5.server.fjf"


#======================业务相关-Config==============================