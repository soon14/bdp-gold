#============================spark-core配置项================================
#设置spark Streaming 应用程序的名字
spark.commons.appName = riskRuleBatch
#spark streaming 每个RDD的分区数（注意配置成kafka topic的分区数）
spark.commons.RDD.num = 10
#spark程序是否优雅的关闭(把接收到的数据处理完毕再关闭spark程序)
spark.commons.gracefully.stop = true
#设置系统打印日记的水平
spark.commons.logLevel= WARN


#设置spark程序的序列化方式(默认java自带)
spark.serializer = org.apache.spark.serializer.KryoSerializer
#内存用来存储的比例,这部分内存中有多少可以用于Memory Store管理RDD Cache的数据
spark.storage.memoryFraction = 0.2
#是否开启调整内存存储比例功能
spark.memory.useLegacyMode = true
#set user memory在整个 executor memory 的占比。（默认 0.6 -> 0.2)，也可调大 executor memory来增加 user memory
spark.memory.fraction = 0.6
#checkpoint的路径和目录(暂定必填)
spark.commons.checkpoint = /user/spark/checkpoint


#============================spark-shuffle================================
#sparkStreaming.Shuffle.manager的类型(hash,sort)
spark.shuffle.manager = sort
#spark.shuffle缓存大小,默认32K 内存充足可以调到64,减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数
spark.shuffle.file.buffer = 64k
#spark shuffle read 拉取属于自己数据时重试的次数
spark.shuffle.io.maxRetries = 3
#spark shuffle read 拉取属于自己数据时重试的间隔
spark.shuffle.io.retryWait = 5s
#spark集群中每个executor中用来shuffle的等操作的内存大小最小比例。shuffle read的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘
spark.shuffle.memoryFraction = 0.6

#======================kafka-config==============================
spark.streaming.realTime.kafkaTopics ="topic-app,canal-data"
#直接读取kafka channel 数据的brokers
spark.streaming.kafkaBrokers ="master212:9092,master213:9092,node214:9092,node215:9092,node216:9092"


#=======================mysql的配置====================
#链接mysql的jdbcURL
spark.straming.jdbc.url ="jdbc:mysql://192.168.99.226:3306/fox-data?useUnicode=true&characterEncoding=utf8&useSSL=false"
#披量写mysql的批量大小
spark.streaming.connect.batch.size = 1000
#连接mysql的用户名
spark.streaming.jdbc.username="root"
#连接mysql的密码
spark.streaming.jdbc.password="123456"
#jdbc driver
spark.streaming.jdbc.driver=com.mysql.jdbc.Driver
#kafka管理offset表
table.kafka.offset ="kafka_offset"


#======================业务相关-Config==============================